{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a06c51e",
   "metadata": {},
   "source": [
    "# Model Fine-Tuning Experiments: Pulmonary Fibrosis Binary Classification\n",
    "\n",
    "This notebook allows you to experiment with and compare different fine-tuning strategies for 3D SE-ResNet50 models on lung CT data. You will:\n",
    "- Train a baseline model\n",
    "- Train an improved model (e.g., with layer unfreezing, optimizer changes, or data augmentation)\n",
    "- Evaluate and compare their performance using accuracy, precision, recall, and confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ca51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Import Required Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import SEResNet50\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from preprocessing import create_train_test_val\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Load and Preprocess Data\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "TEST_SIZE = 0.25\n",
    "VAL_SIZE = 0.5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Load data using preprocessing utilities\n",
    "splits = create_train_test_val(\n",
    "    \"dataset\", \"dataset/labels_binary.csv\",\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "    test_size=TEST_SIZE, val_size=VAL_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "train_loader = splits['train_loader']\n",
    "val_loader = splits['val_loader']\n",
    "test_loader = splits['test_loader']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60546b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Define and Train Models with Multiple Optimizers and Freezing Strategies\n",
    "\n",
    "def set_freeze_strategy(model, strategy):\n",
    "    if strategy == 'none':\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif strategy == 'freeze_layer1':\n",
    "        for name, param in model.named_parameters():\n",
    "            if name.startswith('layer1'):\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "    elif strategy == 'freeze_all_but_fc':\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'fc' in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown freezing strategy: {strategy}\")\n",
    "\n",
    "optimizers_config = {\n",
    "    'AdamW': lambda params, lr: torch.optim.AdamW(params, lr=lr),\n",
    "    'SGD': lambda params, lr: torch.optim.SGD(params, lr=lr, momentum=0.9),\n",
    "}\n",
    "freezing_strategies = ['none', 'freeze_layer1', 'freeze_all_but_fc']\n",
    "learning_rates = [1e-4, 5e-5]\n",
    "num_epochs = 10\n",
    "\n",
    "experiment_results = []\n",
    "experiment_histories = []\n",
    "\n",
    "for opt_name, opt_fn in optimizers_config.items():\n",
    "    for freeze_strategy in freezing_strategies:\n",
    "        for lr in learning_rates:\n",
    "            print(f\"\\n--- Training with {opt_name}, freeze: {freeze_strategy}, lr: {lr} ---\")\n",
    "            model = SEResNet50(spatial_dims=3, in_channels=1, num_classes=2).to(device)\n",
    "            set_freeze_strategy(model, freeze_strategy)\n",
    "            optimizer = opt_fn(filter(lambda p: p.requires_grad, model.parameters()), lr)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            trained_model, history = train_model(\n",
    "                model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs\n",
    "            )\n",
    "            metrics = evaluate_model(trained_model, test_loader, criterion, device, [\"normal\", \"not normal\"])\n",
    "            experiment_results.append({\n",
    "                'optimizer': opt_name,\n",
    "                'freeze_strategy': freeze_strategy,\n",
    "                'learning_rate': lr,\n",
    "                'test_loss': metrics[0],\n",
    "                'accuracy': metrics[1],\n",
    "                'precision': metrics[2],\n",
    "                'recall': metrics[3]\n",
    "            })\n",
    "            experiment_histories.append({\n",
    "                'optimizer': opt_name,\n",
    "                'freeze_strategy': freeze_strategy,\n",
    "                'learning_rate': lr,\n",
    "                'history': history\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe6783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Evaluate Each Model\n",
    "# (Evaluation is performed within the experiment loop in Section 3 for each model/strategy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5: Define and Train Improved Model\n",
    "# Example: Unfreeze all layers and use a lower learning rate with SGD optimizer\n",
    "improved_model = SEResNet50(spatial_dims=3, in_channels=1, num_classes=2)\n",
    "improved_model = improved_model.to(device)\n",
    "\n",
    "# Unfreeze all layers (default), or selectively freeze if desired\n",
    "for param in improved_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Try a different optimizer and learning rate\n",
    "improved_optimizer = torch.optim.SGD(improved_model.parameters(), lr=5e-5, momentum=0.9)\n",
    "improved_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train improved model\n",
    "improved_model, improved_history = train_model(\n",
    "    improved_model, train_loader, val_loader, improved_criterion, improved_optimizer, device, num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6: Evaluate Improved Model\n",
    "improved_metrics = evaluate_model(improved_model, test_loader, improved_criterion, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 7: Compare Model Performance\n",
    "\n",
    "# Create a DataFrame for all experiment metrics\n",
    "metrics_df = pd.DataFrame(experiment_results)\n",
    "display(metrics_df)\n",
    "\n",
    "# Plot accuracy, precision, recall for all experiments\n",
    "plt.figure(figsize=(14, 6))\n",
    "for metric in ['accuracy', 'precision', 'recall']:\n",
    "    plt.plot(metrics_df[metric], label=metric)\n",
    "plt.title('Test Metrics Across Experiments')\n",
    "plt.xlabel('Experiment #')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Optionally, plot training/validation curves for each experiment\n",
    "plt.figure(figsize=(14, 6))\n",
    "for i, exp in enumerate(experiment_histories):\n",
    "    plt.plot(exp['history']['val_acc'], label=f\"{exp['optimizer']}, {exp['freeze_strategy']}, lr={exp['learning_rate']}\")\n",
    "plt.title('Validation Accuracy per Experiment')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy (%)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5750e654",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import all necessary libraries for model training, evaluation, and visualization.\n",
    "\n",
    "## 2. Load and Preprocess Data\n",
    "Load the dataset and prepare train, validation, and test data loaders using the provided preprocessing utilities.\n",
    "\n",
    "## 3. Define and Train Models with Multiple Optimizers and Freezing Strategies\n",
    "This section will automatically train models using different combinations of optimizers (AdamW, SGD), learning rates, and layer freezing strategies (none, freeze layer1, freeze all but final layer). Results and training histories are collected for each experiment.\n",
    "\n",
    "## 4. Evaluate Each Model\n",
    "Each trained model is evaluated on the test set. Metrics including confusion matrix, accuracy, precision, and recall are recorded for each experiment.\n",
    "\n",
    "## 5. Compare Model Performance\n",
    "All experiment results are summarized in a table and visualized with plots to help you identify the best fine-tuning strategy."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
